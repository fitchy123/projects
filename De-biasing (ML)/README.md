Mitigating the gender and race bias of a logistic regression model (scikit-learn) trained on the German adult income dataset to predict whether a person earns above 50K or not. Bias mitigation was done via a re-implementation of Feldman's repair tool. Both zemel fairness and disparate impact could be either fully or partially mitigated using the repair tool, allowing a balance of fairness and accuracy/utility.

Feldmans repair tool: Feldman, M. (2015) ‘Computational Fairness: Preventing Machine-Learned Discrimination’, p. 26.
